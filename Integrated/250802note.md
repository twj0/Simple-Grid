# 微电网DRL控制项目开发笔记

## 项目概述

本项目实现了基于深度强化学习(DRL)的微电网能量管理系统，通过DDPG算法优化电池储能系统的充放电策略，以平衡光伏发电、负载需求和电网交互，同时考虑实时电价和电池寿命。

## 核心文件说明

### 1. 数据生成

- **create_dataset.m**: 生成仿真所需的随机输入数据，包括光伏功率、负载功率和实时电价，并保存为.mat文件。该脚本通过添加日变化因子和小时抖动来生成具有真实随机性的数据。

### 2. 仿真与训练

- **generate_simulation_data.m**: 配置并运行DRL微电网实验，包括加载数据、设置模型参数、定义RL智能体和环境、训练或评估智能体，以及可视化结果。

- **run_drl_experiment.m**: 主要DRL训练脚本，实现了完整的训练流程，包括环境配置、智能体定义、训练参数设置、训练执行和结果评估。

### 3. 问题诊断与修复

- **fix_environment_config.m**: 修复环境配置问题，通过尝试不同的观测维度、重置函数配置和环境创建方法来解决环境初始化问题。

- **fix_observation_issue.m**: 解决观测值类型问题，确保RL智能体接收到正确格式的数值观测值而非SimulationInput对象。

- **fix_mux_block_configuration.m**: 修复Simulink模型中Mux块配置问题，确保输入端口数量与实际连接匹配，解决维度不匹配问题。

- **fix_episode_steps_problem.m**: 解决训练过程中episode steps为0的问题，通过调整仿真时间、求解器配置和智能体参数来确保训练正常进行。

- **find_rl_agent_block.m**: 在Simulink模型中定位RL Agent块，通过多种方法查找和验证RL Agent块的位置和配置。

## 主要问题及修复过程

### 1. 环境配置问题

**问题描述**：环境初始化失败，无法获取正确的观测值。具体表现为创建rlSimulinkEnv时出错，或者reset函数返回非数值类型的观测值。

**修复过程**：
1. **尝试不同的观测维度**：系统地测试了1-7维的观测空间，发现7维观测空间能够正确匹配模型输出。
2. **测试不同的环境创建方法**：
   - 尝试不带重置函数的环境创建
   - 尝试带有重置函数的环境创建（设置电池初始SOC为50%）
   - 使用显式规范创建环境，详细指定观测和动作空间信息
3. **检查RL Agent块内部配置**：
   - 获取并分析RL Agent块的参数和对象属性
   - 检查块的输入/输出端口连接
4. **手动仿真测试**：运行短时仿真，检查模型输出和日志信号
5. **显式环境规范**：最终通过明确指定观测空间为7维、动作空间为1维，并提供详细的名称和描述，成功创建了可用的环境。

**解决方案**：通过显式指定观测和动作空间的详细信息，成功创建了可用的环境。关键是确保观测空间维度与模型输出匹配（7维），并使用正确的数据类型。

### 2. 观测值类型问题

**问题描述**：RL智能体接收到的观测值不是数值类型，而是SimulationInput对象，导致训练无法进行。具体表现为reset函数返回的观测值类型为'Simulink.SimulationInput'而非期望的数值数组。

**修复过程**：
1. **检查RL Agent块配置**：
   - 验证'Agent'参数设置为'agentObj'
   - 确认采样时间设置为3600秒
   - 检查输入/输出端口连接状态
2. **测试不同的环境创建方法**：
   - 标准环境创建（无重置函数）
   - 带重置函数的环境创建
   - 手动设置模型参数后创建环境
3. **手动仿真检查**：
   - 运行短时仿真，分析输出结构
   - 检查日志信号和时间向量
4. **Mux块配置检查与修复**：
   - 识别连接到RL Agent的Mux块
   - 分析Mux块的输入连接和输出配置
   - 将Mux块的'DisplayOption'参数设置为'signals'，确保输出正确的数据类型

**解决方案**：关键修复是将连接到RL Agent块的Mux块的'DisplayOption'参数设置为'signals'，这确保了Mux块输出数值类型而非SimulationInput对象。同时确保RL Agent块的'Agent'参数正确设置为'agentObj'，采样时间设置为3600秒。

### 3. Mux块配置问题

**问题描述**：Mux块的输入端口数量与实际连接不匹配，导致维度错误和训练失败。具体表现为Mux块的'Inputs'参数值与实际连接的输入数量不一致，或者'DisplayOption'设置不正确。

**修复过程**：
1. **全面分析Mux块配置**：
   - 识别模型中所有Mux块
   - 检查每个Mux块的'Inputs'参数和'DisplayOption'设置
   - 分析每个末端连接状态
   - 确定实际连接的输入数量
2. **检查RL Agent块的输入连接**：
   - 分析RL Agent块的输入端口
   - 识别连接到RL Agent的源块
   - 特别关注来自Mux块的输入
3. **修复Mux块配置**：
   - 将Mux块的'Inputs'参数设置为实际连接的输入数量
   - 将'DisplayOption'参数设置为'signals'
   - 对只有一个连接输入的Mux块提出警告（可能不必要）
4. **测试修复效果**：
   - 尝试模型编译
   - 运行短时仿真验证
   - 检查是否仍有错误

**解决方案**：系统地检查并修复所有Mux块，确保'Inputs'参数与实际连接的输入数量匹配，并将'DisplayOption'设置为'signals'。这解决了维度不匹配问题，使模型能够正确编译和运行。

### 4. Episode Steps为0问题

**问题描述**：训练过程中episode steps始终为0，导致无法进行有效训练。这表现为训练统计信息中EpisodeSteps值为0，即使模型能够编译和运行。

**修复过程**：
1. **增加仿真时间**：
   - 将模型的StopTime从3600秒（1小时）增加到7200秒（2小时）
   - 确保仿真时间足够长，能够包含多个训练步骤
2. **配置稳定的求解器**：
   - 设置SolverType为'Variable-step'
   - 使用ode23tb求解器，适合刚性系统
   - 配置合适的RelTol（1e-3）和AbsTol（1e-6）
   - 设置MaxStep为'auto'以优化性能
3. **确保模型能够编译**：
   - 测试模型编译功能
   - 修复可能导致编译失败的问题
4. **检查并修复RL Agent块配置**：
   - 确保'Agent'参数设置为'agentObj'
   - 验证所有输入端口都已连接
   - 检查采样时间设置
5. **创建简化的测试智能体**：
   - 定义简化的观测和动作空间
   - 创建基本的Actor-Critic网络结构
   - 使用最小化的训练选项
6. **测试环境重置和单个episode**：
   - 验证环境重置功能
   - 运行单个训练episode（最大步数设为3）
   - 检查EpisodeSteps是否大于0

**解决方案**：关键修复包括增加仿真时间至少2小时（7200秒），使用变步长ode23tb求解器以提高数值稳定性，确保RL Agent块正确配置，以及验证模型能够成功编译。这些修改共同解决了episode steps为0的问题。

## 经验总结

1. **Simulink模型配置至关重要**：确保模型中的块正确配置，特别是Mux块的输入数量与实际连接匹配，DisplayOption设置为signals。

2. **仿真时间设置影响训练**：仿真时间过短会导致episode steps为0，建议设置足够长的仿真时间（至少2小时）。

3. **求解器选择影响稳定性**：变步长求解器（如ode23tb）对于复杂的微电网模型更为稳定，合适的容差设置也很重要。

4. **观测空间维度需要正确匹配**：确保RL智能体的观测空间维度与模型输出匹配，本项目中为7维。

5. **调试过程需要系统性方法**：从简单到复杂，逐步排查和修复问题，包括尝试不同的配置选项和测试简化场景。

## 后续改进方向

1. 优化网络结构，提高训练效率和性能
2. 尝试不同的DRL算法（如SAC、TD3）
3. 增加更多的环境变量和约束条件
4. 改进奖励函数设计，更好地平衡经济性和电池寿命
5. 实现多智能体协作控制